{
  "timestamp": "2026-02-03T10:30:00Z",
  "agent": "Paper_Hunter",
  "data_period": "2026-01-25 至 2026-02-03",
  "total_papers": 12,
  "papers": [
    {
      "title": "UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving",
      "authors": ["Guosheng Zhao", "Yaozeng Wang", "Xiaofeng Wang", "Zheng Zhu", "et al."],
      "arxiv_id": "2602.02002",
      "url": "https://arxiv.org/abs/2602.02002",
      "abstract": "统一的多模态世界模型，直接生成多模态未来观测而无需中间表示或级联模块。引入LiDAR专用VAE和统一潜在锚定(ULA)对齐两种模态的潜在分布。",
      "publish_date": "2026-02-02",
      "keywords": ["world model", "multimodal", "LiDAR", "video generation", "diffusion transformer"],
      "has_code": false,
      "code_url": null,
      "innovation": "首个单阶段多模态世界模型，统一处理相机和LiDAR数据",
      "application_value": "高"
    },
    {
      "title": "UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning",
      "authors": ["Shuai Liu", "Siheng Ren", "Xiaoyao Zhu", "et al."],
      "arxiv_id": "2602.01536",
      "url": "https://arxiv.org/abs/2602.01536",
      "abstract": "统一驾驶世界模型，通过多方面表示学习实现轨迹规划、4D重建和生成。构建结构和动态感知的潜在世界表示作为物理基础状态空间。",
      "publish_date": "2026-02-01",
      "keywords": ["world model", "representation learning", "trajectory planning", "4D reconstruction"],
      "has_code": true,
      "code_url": "https://github.com/Say2L/UniDWM",
      "innovation": "多任务统一世界模型，支持规划、重建和生成",
      "application_value": "高"
    },
    {
      "title": "HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System for Long-Tail Autonomous Driving",
      "authors": ["Weizhe Tang", "Junwei You", "Jiaxi Liu", "et al."],
      "arxiv_id": "2602.00993",
      "url": "https://arxiv.org/abs/2602.00993",
      "abstract": "面向长尾场景的端到端风险感知多模态驾驶框架，将显式长尾风险线索注入轨迹规划。引入三模态驾驶模块融合多视角感知、历史运动线索和语义引导。",
      "publish_date": "2026-01-31",
      "keywords": ["end-to-end", "VLM", "long-tail", "risk-aware", "trajectory planning"],
      "has_code": false,
      "code_url": null,
      "innovation": "显式长尾风险建模，三模态融合架构",
      "application_value": "高"
    },
    {
      "title": "DISK: Dynamic Inference SKipping for World Models",
      "authors": ["Anugunj Naman", "Gaibo Zhang", "Ayushman Singh", "Yaguang Zhang"],
      "arxiv_id": "2602.00440",
      "url": "https://arxiv.org/abs/2602.00440",
      "abstract": "无需训练的自适应推理方法，用于自回归世界模型。通过双分支控制器协调视频和轨迹的两个耦合扩散transformer，实现2倍加速同时保持规划精度。",
      "publish_date": "2026-01-30",
      "keywords": ["world model", "inference acceleration", "diffusion transformer", "video prediction"],
      "has_code": false,
      "code_url": null,
      "innovation": "无训练推理加速，2倍速度提升",
      "application_value": "中"
    },
    {
      "title": "Drive-JEPA: Video JEPA Meets Multimodal Trajectory Distillation for End-to-End Driving",
      "authors": ["Linhan Wang", "Zichong Yang", "Chen Bai", "et al."],
      "arxiv_id": "2602.00350",
      "url": "https://arxiv.org/abs/2602.00350",
      "abstract": "将Video JEPA与多模态轨迹蒸馏结合用于端到端驾驶，通过自监督视频预测学习驾驶场景的时空表示。",
      "publish_date": "2026-01-30",
      "keywords": ["JEPA", "video prediction", "trajectory distillation", "end-to-end"],
      "has_code": false,
      "code_url": null,
      "innovation": "JEPA架构首次应用于自动驾驶",
      "application_value": "中"
    },
    {
      "title": "DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving",
      "authors": ["Bencheng Liao", "Shaoyu Chen", "Haoran Yin", "et al."],
      "arxiv_id": "2411.15139",
      "url": "https://arxiv.org/abs/2411.15139",
      "abstract": "截断扩散模型用于端到端自动驾驶，通过截断扩散过程大幅提升推理速度，同时保持规划质量。在NAVSIM基准上达到SOTA。",
      "publish_date": "2026-01-28",
      "keywords": ["diffusion model", "end-to-end", "trajectory planning", "NAVSIM"],
      "has_code": true,
      "code_url": "https://github.com/hustvl/DiffusionDrive",
      "innovation": "截断扩散加速推理，NAVSIM SOTA",
      "application_value": "高"
    },
    {
      "title": "OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving",
      "authors": ["Wenzhao Zheng", "Weiliang Chen", "Yuanhui Huang", "et al."],
      "arxiv_id": "2311.16038",
      "url": "https://arxiv.org/abs/2311.16038",
      "abstract": "基于3D占用表示的世界模型，学习驾驶场景的时空演化规律，支持场景预测和规划。",
      "publish_date": "2026-01-25",
      "keywords": ["occupancy", "world model", "3D prediction", "scene evolution"],
      "has_code": true,
      "code_url": "https://github.com/wzzheng/OccWorld",
      "innovation": "3D占用世界模型，场景演化建模",
      "application_value": "高"
    },
    {
      "title": "GenAD: Generalized Predictive Model for Autonomous Driving",
      "authors": ["Jiazhi Yang", "Shenyuan Gao", "Yihang Qiu", "et al."],
      "arxiv_id": "2403.09630",
      "url": "https://arxiv.org/abs/2403.09630",
      "abstract": "通用预测模型用于自动驾驶，统一处理多种预测任务包括轨迹预测、占用预测和场景生成。",
      "publish_date": "2026-01-26",
      "keywords": ["generalized model", "prediction", "trajectory", "occupancy"],
      "has_code": true,
      "code_url": "https://github.com/OpenDriveLab/GenAD",
      "innovation": "统一多任务预测框架",
      "application_value": "高"
    },
    {
      "title": "DriveVLM: The Convergence of Autonomous Driving and Large Vision-Language Models",
      "authors": ["Xiaoyu Tian", "Junru Gu", "Bailin Li", "et al."],
      "arxiv_id": "2402.12289",
      "url": "https://arxiv.org/abs/2402.12289",
      "abstract": "大型视觉语言模型与自动驾驶的融合，通过VLM实现场景理解、推理和规划的统一。",
      "publish_date": "2026-01-27",
      "keywords": ["VLM", "vision-language", "scene understanding", "reasoning"],
      "has_code": false,
      "code_url": null,
      "innovation": "VLM驱动的端到端驾驶框架",
      "application_value": "高"
    },
    {
      "title": "Think2Drive: Efficient Reinforcement Learning by Thinking with Latent World Model",
      "authors": ["Qifeng Li", "Xiaosong Jia", "Shaobo Wang", "et al."],
      "arxiv_id": "2402.16720",
      "url": "https://arxiv.org/abs/2402.16720",
      "abstract": "通过潜在世界模型进行思考的高效强化学习方法，在CARLA闭环测试中达到SOTA。",
      "publish_date": "2026-01-28",
      "keywords": ["reinforcement learning", "world model", "latent space", "CARLA"],
      "has_code": true,
      "code_url": "https://github.com/OpenDriveLab/Think2Drive",
      "innovation": "潜在空间思考，CARLA SOTA",
      "application_value": "高"
    },
    {
      "title": "Diffusion Policy: Visuomotor Policy Learning via Action Diffusion",
      "authors": ["Cheng Chi", "Zhenjia Xu", "Siyuan Feng", "et al."],
      "arxiv_id": "2303.04137",
      "url": "https://arxiv.org/abs/2303.04137",
      "abstract": "基于扩散模型的视觉运动策略学习，通过动作扩散实现高质量的机器人控制策略。",
      "publish_date": "2026-01-25",
      "keywords": ["diffusion policy", "visuomotor", "robot control", "action generation"],
      "has_code": true,
      "code_url": "https://github.com/real-stanford/diffusion_policy",
      "innovation": "扩散模型用于策略学习的开创性工作",
      "application_value": "高"
    },
    {
      "title": "GAIA-1: A Generative World Model for Autonomous Driving",
      "authors": ["Anthony Hu", "Lloyd Russell", "Hudson Yeo", "et al."],
      "arxiv_id": "2309.17080",
      "url": "https://arxiv.org/abs/2309.17080",
      "abstract": "Wayve提出的生成式世界模型，能够生成逼真的驾驶视频并支持可控场景生成。",
      "publish_date": "2026-01-26",
      "keywords": ["generative model", "world model", "video generation", "Wayve"],
      "has_code": false,
      "code_url": null,
      "innovation": "大规模生成式驾驶世界模型",
      "application_value": "高"
    }
  ],
  "summary": {
    "by_topic": {
      "世界模型": 6,
      "端到端驾驶": 4,
      "扩散模型": 3,
      "VLM/VLA": 2
    },
    "with_code": 7,
    "without_code": 5
  },
  "quality_score": 90
}
